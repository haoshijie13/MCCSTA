{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c570cb47-b735-4353-aa18-634dd09c0cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely import geometry\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5e9647e-7a5e-4eff-8cd7-09a9f7d91164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the most frequently-occurring value in each row of a 2D NumPy arra\n",
    "def bincount2D_vectorized(a):\n",
    "    N = a.max()+1\n",
    "    a_offs = a + np.arange(a.shape[0])[:,None]*N\n",
    "    return np.bincount(a_offs.ravel(), minlength=a.shape[0]*N).reshape(-1,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9d59a9d-4f97-49bb-81e2-0d449c690c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search for values in a list that exist in a 2D NumPy array\n",
    "def isin2d(arr1,arr2):\n",
    "    return (arr1==arr2[:,None]).all(2).any(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d32160f9-d8fd-4364-9e86-ed43c6b2157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smooth a vector by inserting the mid - point between every two adjacent points\n",
    "def smooth_border(vertex_input,coordinate_input):\n",
    "    coordinate_output = []\n",
    "    for i in range(0,len(vertex_input)):\n",
    "        if np.isin(vertex_input[i],cut_vertex) or np.isin(vertex_input[i],more_vertex):\n",
    "        #if np.isin(vertex_input[i],more_vertex) or :\n",
    "            coordinate_output = coordinate_output + [coordinate_input[i]]\n",
    "        else:\n",
    "            coordinate_output = coordinate_output + [(coordinate_input[i]+coordinate_input[i-1])/2]\n",
    "    return np.array(coordinate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6455819b-06f6-4608-9131-8ca571fafa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_border(edge_def,flatmap_list_def_input):\n",
    "    flatmap_list_def = flatmap_list_def_input.copy()\n",
    "    border_def = np.array([edge_def[0]])\n",
    "    multi_plot = False\n",
    "    vertex = [border_def[0,0]]\n",
    "    \n",
    "    for i in range(1,len(edge_def)):\n",
    "        last_edge_def = border_def[-1]\n",
    "        next_edge_def = edge_def[(np.isin(edge_def[:,0],last_edge_def)|np.isin(edge_def[:,1],last_edge_def))&(~isin2d(edge_def,border_def))&\n",
    "        ((edge_def[:,0]==vertex[-1])|(edge_def[:,1]==vertex[-1]))]\n",
    "        if len(next_edge_def)==0:\n",
    "            multi_plot = True\n",
    "            break\n",
    "        border_def = np.concatenate([border_def,np.array([next_edge_def[0]])])\n",
    "        vertex = vertex + [border_def[-1][border_def[-1]!=vertex[-1]][0]]\n",
    "\n",
    "    if len(vertex)>2:\n",
    "        flatmap_list_def = flatmap_list_def + [[smooth_border(vertex,flatmap[vertex])]]\n",
    "    if multi_plot:\n",
    "        edge_def = edge_def[~isin2d(edge_def,border_def)]\n",
    "        flatmap_list_def = sort_border(edge_def,flatmap_list_def)\n",
    "    return flatmap_list_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "86f31921-4f0c-4cb1-ba41-902ca6cda139",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a GeoDataFrame\n",
    "#Input mesh: n x 3 array. n is triangle count, 3 are flatmap coordinate indices.\n",
    "#Input flatmap: m x 3 array. m is vertex count, 3 are vertex coords (x, y, z with z usually 0).\n",
    "#Input label: m - length array. Labels each vertex numerically.\n",
    "#Input label_list & rename_list: Used for label renaming & merging. E.g., [1,2,3] and [\"A\",\"A\",\"B\"] merge 1,2 to \"A\" and rename 3 to \"B\".\n",
    "def create_GeoDataFrame(mesh,flatmap,label,label_list,rename_list):\n",
    "    cut_edge = pd.DataFrame(np.sort(np.concatenate([mesh[:,[0,1]],mesh[:,[1,2]],mesh[:,[0,2]]])),columns=['v1','v2'])\n",
    "    cut_edge['edge'] = cut_edge['v1'].map(str) + '_' + cut_edge['v2'].map(str)\n",
    "    #Retrieve the distinct edges that form the boundary of the mesh\n",
    "    cut_edge = cut_edge.drop_duplicates(subset=['edge'],keep=False)\n",
    "    cut_edge = np.array(cut_edge[['v1','v2']])\n",
    "    cut_vertex = np.unique(cut_edge.flatten())\n",
    "\n",
    "    mesh_label = label[mesh]\n",
    "    mesh_label = np.argmax(bincount2D_vectorized(mesh_label),axis=1)\n",
    "    all_edge = []\n",
    "    for n in np.unique(label):\n",
    "        n_mesh = mesh[mesh_label==n]\n",
    "        if len(n_mesh)==0:\n",
    "            continue\n",
    "        if n==0:\n",
    "            continue\n",
    "        edge = pd.DataFrame(np.sort(np.concatenate([n_mesh[:,[0,1]],n_mesh[:,[1,2]],n_mesh[:,[0,2]]])),columns=['v1','v2'])\n",
    "        edge['edge'] = edge['v1'].map(str) + '_' + edge['v2'].map(str)\n",
    "        edge = edge.drop_duplicates(subset=['edge'],keep=False)\n",
    "        all_edge = all_edge + [edge]\n",
    "        \n",
    "    all_edge = pd.concat(all_edge)\n",
    "    all_vertex = np.array(all_edge[['v1','v2']]).flatten()\n",
    "    more_vertex = np.arange(0,max(all_vertex)+1)[np.bincount(all_vertex)>=6]\n",
    "    \n",
    "    mesh_label = label[mesh]\n",
    "    mesh_label = np.argmax(bincount2D_vectorized(mesh_label),axis=1)\n",
    "\n",
    "    Polygon_list = []\n",
    "    region_index = []\n",
    "    region_label = pd.DataFrame({'Index':label_list,'new_name':rename_list})\n",
    "    for n in pd.unique(region_label['new_name']):\n",
    "        n_mesh = mesh[np.isin(mesh_label,np.array(region_label[region_label['new_name']==n]['Index']))]\n",
    "        if len(n_mesh)==0:\n",
    "            continue\n",
    "        edge = pd.DataFrame(np.sort(np.concatenate([n_mesh[:,[0,1]],n_mesh[:,[1,2]],n_mesh[:,[0,2]]])),columns=['v1','v2'])\n",
    "        edge['edge'] = edge['v1'].map(str) + '_' + edge['v2'].map(str)\n",
    "        edge = edge.drop_duplicates(subset=['edge'],keep=False)\n",
    "        edge = np.array(edge[['v1','v2']])\n",
    "        flatmap_list = []\n",
    "        flatmap_list = sort_border(edge,flatmap_list)\n",
    "        if len(flatmap_list)==1:\n",
    "            Polygon_list = Polygon_list + [geometry.Polygon(flatmap_list[0][0])]\n",
    "        else:\n",
    "            Polygon_list = Polygon_list + [geometry.MultiPolygon(flatmap_list)] \n",
    "        region_index = region_index + [n]\n",
    "\n",
    "    cq = gpd.GeoSeries(Polygon_list,\n",
    "                     crs='EPSG:4326')\n",
    "    df = pd.DataFrame({'region':region_index})\n",
    "    df = gpd.GeoDataFrame(df,geometry=cq)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23684107-931f-4b37-ae51-39ee3cf5412a",
   "metadata": {},
   "source": [
    "<font size=10>---------------Marmoset flatmap-------------<font size=10>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "a59031d3-0931-451f-a308-dee2aa76d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#marmoset MRI flatmap data, download from https://db.cngb.org/stomics/mbcsta/download/ or https://marmosetbrainmapping.org/data.html#alldata\n",
    "flatmap = nib.load(\"data/MRI_raw_data/marmoset/surfFS.rh.full.flat.patch.surf.gii\")\n",
    "label = nib.load(\"data/MRI_raw_data/marmoset/surfFS.rh.MBM_cortex_vPaxinos.label.gii\")\n",
    "region_name = pd.read_csv('data/MRI_raw_data/marmoset/atlas_MBM_cortex_vPaxinos.txt',sep='\\s+',header=None)\n",
    "region_name = region_name[region_name[1]!='background']\n",
    "VL_change = pd.read_csv('Tabledata/All2VL.txt',sep='\\s+')\n",
    "VL_change = VL_change[VL_change['species']=='Marmoset']\n",
    "VL_change.index = VL_change['region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "bfc234e3-7b2f-405e-b9a6-6b29ad42f79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the array from the nib object\n",
    "mesh = flatmap.darrays[1].data\n",
    "flatmap = flatmap.darrays[0].data[:,0:2]\n",
    "label = np.round(label.darrays[0].data,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "d7423196-e179-4032-afa8-d734317345d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#horizontal mirror flatmap coordiante\n",
    "mirror_matrix = np.array([[-1, 0], [0, 1]])\n",
    "flatmap = np.dot(flatmap, mirror_matrix.T)\n",
    "#rotation flatmap coordiante 75Â°\n",
    "theta = np.radians(75)\n",
    "rotation_matrix = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                            [np.sin(theta), np.cos(theta)]])\n",
    "flatmap = np.dot(flatmap, rotation_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "14660e89-ccdd-4219-b866-f9f1db473ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the marmoset geodataframe\n",
    "df = create_GeoDataFrame(mesh,flatmap,label,region_name[0],region_name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "27c2244e-4e13-46d6-a0a0-f171114b9fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add uniform_region label to flatmap\n",
    "df['VL'] = [VL_change.loc[i]['Uniform_region'] for i in df['region'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "0d56607f-9463-4ca9-be28-864458089b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as shp file, pre-processed files can be downloaded from https://db.cngb.org/stomics/mbcsta/download/ or https://github.com/haoshijie13/MCCSTA/tree/main/Stereo_analysis\n",
    "df.to_file('data/MRI_shp_file/Marmoset.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6498af-fa74-42db-a166-b21a71bc1bca",
   "metadata": {},
   "source": [
    "<font size=10>---------------Macaque flatmap-------------<font size=10>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d240e7-0d03-43e0-b788-09c34c01f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "bc36bccf-4fb0-4c4c-a393-b1f9d7e2749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#macaque MRI flatmap data, download from https://db.cngb.org/stomics/mbcsta/download/ or https://www.scidb.cn/en/detail?dataSetId=f6eead10c2f84e9d91951cee2837048f\n",
    "flatmap = nib.load(\"data/MRI_raw_data/macaque/civm.L.flat.164k_fs_LR.surf.gii\")\n",
    "label = nib.load(\"data/MRI_raw_data/macaque/d1_D99_atlas_in_BNA_L2.shape.gii\")\n",
    "region_name = pd.read_csv(\"data/MRI_raw_data/macaque/region_label.txt\",sep='\\t',header=0)\n",
    "VL_change = pd.read_csv('Tabledata/All2VL.txt',sep='\\s+')\n",
    "VL_change = VL_change[VL_change['species']=='Macaque']\n",
    "VL_change.index = VL_change['region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d8964050-cf6a-48f0-b9e1-895565f647eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = flatmap.darrays[1].data\n",
    "flatmap = flatmap.darrays[0].data[:,0:2]\n",
    "#remove float point\n",
    "label = np.round(label.darrays[0].data,0)\n",
    "\n",
    "#imputation the NA value in label by 10 nearest point\n",
    "ref_label = label[np.isin(label,region_name['Index'])].astype('int')\n",
    "ref_flatmap = flatmap[np.isin(label,region_name['Index'])]\n",
    "kdt = KDTree(ref_flatmap, leaf_size=30, metric='euclidean')\n",
    "result = kdt.query(flatmap,k=10, return_distance=False)\n",
    "for i in range(0,2):\n",
    "    query_label = np.argmax(bincount2D_vectorized(ref_label[result]),axis=1)\n",
    "    label = query_label.copy().astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "14697181-6598-470f-aebe-8261481d5be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the marmoset geodataframe\n",
    "df = create_GeoDataFrame(mesh,flatmap,label,region_name['Index'],region_name['new_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8960f5f3-da7c-4c96-852c-644e9bf6a323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add uniform_region label to flatmap\n",
    "df['VL'] = [VL_change.loc[i.split('-')[0]]['Uniform_region'] for i in df['region'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cd52f99b-32a6-4dba-bc13-d1fe7483ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as shp file, pre-processed files can be downloaded from https://db.cngb.org/stomics/mbcsta/download/ or https://github.com/haoshijie13/MCCSTA/tree/main/Stereo_analysis\n",
    "df.to_file('data/MRI_shp_file/Macaque.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22c396a-8ee2-4125-bb46-696b0b82483c",
   "metadata": {},
   "source": [
    "<font size=10>---------------Human flatmap-------------<font size=10>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d87a334f-8587-4d34-9f99-539de40795dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    }
   ],
   "source": [
    "#human MRI flatmap data, download from https://db.cngb.org/stomics/mbcsta/download/ or https://balsa.wustl.edu/WN56\n",
    "flatmap = nib.load(\"data/MRI_raw_data/human/Q1-Q6_RelatedParcellation210.L.flat.32k_fs_LR.surf.gii\")\n",
    "label_raw = nib.load(\"data/MRI_raw_data/human/Q1-Q6_RelatedParcellation210.L.CorticalAreas_dil_Colors.32k_fs_LR.dlabel.nii\")\n",
    "region_name = pd.read_csv(\"data/MRI_raw_data/human/region_list.txt\",sep='\\t',header=None)\n",
    "VL_change = pd.read_csv('Tabledata/All2VL.txt',sep='\\s+')\n",
    "VL_change = VL_change[VL_change['species']=='Human']\n",
    "VL_change.index = VL_change['region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "434e939b-2718-4fe3-a467-fb7b7a491b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = flatmap.darrays[1].data\n",
    "flatmap = flatmap.darrays[0].data[:,0:2]\n",
    "#get human label from nib object\n",
    "label = np.zeros((label_raw.header.get_axis(1).vertex.max()+1),dtype=int)\n",
    "label[label_raw.header.get_axis(1).vertex] = label_raw.get_fdata()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "786865ff-3c69-4efb-8141-ddb6eb37d397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the marmoset geodataframe\n",
    "df = create_GeoDataFrame(mesh,flatmap,label,region_name[0],region_name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1355442e-ba0a-4dc2-a724-32d0e06dcb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add uniform_region label to flatmap\n",
    "df['VL'] = [VL_change.loc[i]['Uniform_region'] for i in df['region'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8a2d7603-9f0c-4315-a0cb-4dddc9501634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as shp file, pre-processed files can be downloaded from https://db.cngb.org/stomics/mbcsta/download/ or https://github.com/haoshijie13/MCCSTA/tree/main/Stereo_analysis\n",
    "df.to_file('data/MRI_shp_file/Human.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a7b312-d7f6-4bc5-a6b3-aba55a36d1f1",
   "metadata": {},
   "source": [
    "<font size=10>---------------Mouse flatmap-------------<font size=10>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cd099bf9-f618-44ae-8b51-295f125982cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5d1bde5b-25c6-4a5b-99dc-dfdde46dcf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#human MRI flatmap data, download from https://db.cngb.org/stomics/mbcsta/download/\n",
    "img = io.imread('data/MRI_raw_data/mouse/flatmap_dorsal.tif')\n",
    "region_label = pd.read_csv('data/MRI_raw_data/mouse/region_name.txt',sep='\\t',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "039a9f7e-428b-45e6-8d81-5ffc25df4bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_list = []\n",
    "for label in region_label['id']:\n",
    "    region_img = img.copy()\n",
    "    region_img[region_img!=label] = 0\n",
    "    region_img[region_img==label] = 255\n",
    "    region_img = region_img.astype('uint8')\n",
    "    contours, hierarchy = cv2.findContours(region_img,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE) \n",
    "    if(len(contours)>1):\n",
    "        multipoly = []\n",
    "        for i in range(0,len(contours)):\n",
    "            if contours[i].shape[0] < 4:\n",
    "                continue\n",
    "            multipoly = multipoly + [geometry.Polygon(-np.reshape(newshape=(len(contours[i]),2),a=contours[i]))]\n",
    "        multipoly = geometry.MultiPolygon(multipoly)\n",
    "        poly_list = poly_list + [multipoly]\n",
    "    else:\n",
    "        singlepoly = geometry.Polygon(-np.reshape(newshape=(len(contours[0]),2),a=contours[0]))\n",
    "        poly_list = poly_list + [singlepoly]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "22555c1e-2a81-4d01-b672-0203268ae7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cq = gpd.GeoSeries(poly_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "aca00e5d-8584-44ef-aa1f-788221c9b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.GeoDataFrame(region_label['id'],geometry=cq)\n",
    "df[['name','region']] = region_label[['name','region']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d96c9d10-357a-4dd8-8a44-a125c01b35ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/SSD4Ta/home/huangzhi/anaconda3/envs/work/lib/python3.11/site-packages/pyogrio/geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n"
     ]
    }
   ],
   "source": [
    "#save as shp file, pre-processed files can be downloaded from https://db.cngb.org/stomics/mbcsta/download/ or https://github.com/haoshijie13/MCCSTA/tree/main/Stereo_analysis\n",
    "df.to_file('data/MRI_shp_file/Mouse.shp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
